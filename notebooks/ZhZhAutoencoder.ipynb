{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jenniebn/wordLevelTrans/blob/main/notebooks/ZhZhAutoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kuC0h3PWpGn7"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import copy\n",
        "import json\n",
        "import time\n",
        "import math\n",
        "import torch\n",
        "import random\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as TF\n",
        "from torch import nn, optim, tensor\n",
        "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxfPPKa5JUDX",
        "outputId": "3dce3ace-8a86-403d-8213-caf59775f6bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# TODO 0: Mount your Google Drive; this allows the runtime environment to access your drive.\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# NOTE: Make sure your path does NOT include a '/' at the end!\n",
        "base_dir = \"/content/gdrive/MyDrive/wordLevelTrans\"\n",
        "sys.path.append(base_dir)\n",
        "## END TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7v0h5pJNT_r",
        "outputId": "7bc57cf6-0faf-4b45-f819-b041e27b52fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Feb 19 05:29:53 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla V100-SXM2-16GB           Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0              25W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2sohmSWOn83",
        "outputId": "c35d3a66-fa00-4417-9d6b-3f2565bb81bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UnEBpWxj2f6"
      },
      "source": [
        "# 1. Load Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRy1Ff7jf52K"
      },
      "outputs": [],
      "source": [
        "with open('data/zh_embedding.pkl', 'rb') as file:\n",
        "    zh_embedding = pickle.load(file)\n",
        "    file.close()\n",
        "with open('data/vocab_zh.pkl', 'rb') as file:\n",
        "    vocab_zh = pickle.load(file)\n",
        "    file.close()\n",
        "with open('data/word_to_index_zh.pkl', 'rb') as file:\n",
        "    word_to_index_zh = pickle.load(file)\n",
        "    file.close()\n",
        "with open('data/idx_to_embed_zh.pkl', 'rb') as file:\n",
        "    idx_to_embed_zh = pickle.load(file)\n",
        "    file.close()\n",
        "with open('data/en_embedding.pkl', 'rb') as file:\n",
        "    en_embedding = pickle.load(file)\n",
        "    file.close()\n",
        "with open('data/vocab_en.pkl', 'rb') as file:\n",
        "    vocab_en = pickle.load(file)\n",
        "    file.close()\n",
        "with open('data/word_to_index_en.pkl', 'rb') as file:\n",
        "    word_to_index_en = pickle.load(file)\n",
        "    file.close()\n",
        "with open('data/idx_to_embed_en.pkl', 'rb') as file:\n",
        "    idx_to_embed_en = pickle.load(file)\n",
        "    file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGlRXUqsf662",
        "outputId": "8188fbca-bb1a-4680-ed4a-f1f8e4030c01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The first 10 words in the English vocabulary are: {'and': 0, 'of': 1, 'a': 2, 'in': 3, 'is': 4, 'to': 5, 'for': 6, 'that': 7, 's': 8, 'with': 9}\n",
            "EN vocab size is 82615\n",
            "The index for the English word 'cannot' is: 700\n"
          ]
        }
      ],
      "source": [
        "vocab_en = list(word_to_index_en.keys())\n",
        "vocab_size_en = len(vocab_en)\n",
        "first10pairs = {k: word_to_index_en[k] for k in list(word_to_index_en)[:10]}\n",
        "print(\"The first 10 words in the English vocabulary are:\", first10pairs)\n",
        "print(\"EN vocab size is\", vocab_size_en)\n",
        "print(\"The index for the English word 'cannot' is:\", word_to_index_en[\"cannot\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSrviNu8f9nG",
        "outputId": "bcc4bb92-e55e-4c36-dc13-90e279104f46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The first 10 words in the Chinese vocabulary are: {'的': 0, '了': 1, '在': 2, '是': 3, '和': 4, '有': 5, '章': 6, '就': 7, '第': 8, '也': 9}\n",
            "ZH vocab size is 95685\n",
            "The index for the Chinese word '的' is: 0\n"
          ]
        }
      ],
      "source": [
        "vocab_zh = list(word_to_index_zh.keys())\n",
        "vocab_size_zh = len(vocab_zh)\n",
        "first10pairs = {k: word_to_index_zh[k] for k in list(word_to_index_zh)[:10]}\n",
        "print(\"The first 10 words in the Chinese vocabulary are:\", first10pairs)\n",
        "print(\"ZH vocab size is\", vocab_size_zh)\n",
        "print(\"The index for the Chinese word '的' is:\", word_to_index_zh['的'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMp1EQN9nXe5",
        "outputId": "7b32be1f-fdf5-4bdc-9654-9d6c06571f37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'petard': ['作茧自缚', '以子之矛，攻子之盾', '吐丝自缚'], 'northeasterly': ['向东北的', '东北风'], 'relinquishment': ['放弃'], 'readers': ['读者'], 'thawed': ['融化'], 'improvised': ['自制', '即席'], 'webbed': ['有蹼的'], 'extolled': ['赞扬'], 'votive': ['奉献的', '还愿'], 'ardour': ['激情', '热忱']}\n"
          ]
        }
      ],
      "source": [
        "# Load the golden set\n",
        "with open('data/golden_set.json', encoding=\"utf-8-sig\") as in_file:\n",
        "  # returns JSON object as a dictionary\n",
        "    golden_set = json.load(in_file)\n",
        "\n",
        "# Closing file\n",
        "in_file.close()\n",
        "\n",
        "first10pairs = {k: golden_set[k] for k in list(golden_set)[:10]}\n",
        "print(first10pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNtUHln1gdmj",
        "outputId": "780fb755-cf28-4d36-dd28-9dd1e24d1b15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 46409 unique English words in our golden set\n"
          ]
        }
      ],
      "source": [
        "# en_vocab_list is list of unique English words in golden set\n",
        "gold_en_list = list(golden_set.keys())\n",
        "\n",
        "# length of English vocabulary\n",
        "gold_en_size = len(gold_en_list)\n",
        "print(\"There are\", gold_en_size, \"unique English words in our golden set\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUokaeXTah5i"
      },
      "outputs": [],
      "source": [
        "# Load the partitioned golden set\n",
        "with open('data/partitioned_golden_set.json', encoding=\"utf-8-sig\") as in_file:\n",
        "  # returns JSON object as a dictionary\n",
        "    partitioned_golden_set = json.load(in_file)\n",
        "\n",
        "# Closing file\n",
        "in_file.close()\n",
        "\n",
        "concrete_emotion_label = partitioned_golden_set['concrete']['emotion_label']\n",
        "concrete_emotion_laden = partitioned_golden_set['concrete']['emotion_laden']\n",
        "concrete_other = partitioned_golden_set['concrete']['other']\n",
        "abstract_emotion_label = partitioned_golden_set['abstract']['emotion_label']\n",
        "abstract_emotion_laden = partitioned_golden_set['abstract']['emotion_laden']\n",
        "abstract_other = partitioned_golden_set['abstract']['other']\n",
        "unknown_emotion_label = partitioned_golden_set['unknown_abstraction']['emotion_label']\n",
        "unknown_emotion_laden = partitioned_golden_set['unknown_abstraction']['emotion_laden']\n",
        "unknown_other = partitioned_golden_set['unknown_abstraction']['other']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2O66hsYapw0"
      },
      "outputs": [],
      "source": [
        "# Load the lemmatized golden set\n",
        "with open('data/lemmatized_golden_set.json', encoding=\"utf-8-sig\") as in_file:\n",
        "  # returns JSON object as a dictionary\n",
        "    lemmatized_golden_set = json.load(in_file)\n",
        "\n",
        "# Closing file\n",
        "in_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvzl6BKJkERP"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(4)\n",
        "np.random.seed(4)\n",
        "random.seed(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1DbO-KMBKCu"
      },
      "source": [
        "# 2. Custom Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jigMIVJWBM1_"
      },
      "outputs": [],
      "source": [
        "# Define dataset to load to dataloader\n",
        "class TrainData(Dataset):\n",
        "\n",
        "    def __init__(self, trained_data):\n",
        "        \"\"\"Loads the data from the pretrained model\"\"\"\n",
        "        self.data = trained_data\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Returns the datapoint at a given index\"\"\"\n",
        "        return self.data[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Returns the number of datapoints in the dataset\"\"\"\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nsbFbONBNy-"
      },
      "outputs": [],
      "source": [
        "# Define collate_batch for batch of training samples\n",
        "\n",
        "def wordToindex(word):\n",
        "    \"\"\"Get the corresponding index for the Chinese word\"\"\"\n",
        "    return word_to_index_zh[word]\n",
        "\n",
        "def collate_batch(batch):\n",
        "    \"\"\"Converts a batch of data into packed PyTorch tensor format,\n",
        "    and collates the results by index, word, and one-hot vector\n",
        "    for use in an Autoencoder.\n",
        "    \"\"\"\n",
        "    # Initialize lists that separate out the 3 components\n",
        "    index_list      = list()\n",
        "    word_list       = list()\n",
        "\n",
        "    for word in batch:\n",
        "        # Convert to PyTorch format\n",
        "        index   = wordToindex(word)\n",
        "\n",
        "        # Add converted data to separate component lists\n",
        "        index_list.append(index)\n",
        "        word_list.append(word)\n",
        "\n",
        "    # Convert to mini-batch tensors\n",
        "    index_tensor = torch.tensor(index_list, dtype=torch.int64)\n",
        "\n",
        "    return (word_list, index_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zEtiOF7ykeo"
      },
      "source": [
        "# 3. Create latent spaces + relative embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6UF0s0yyn8y",
        "outputId": "44d27ab6-29dc-4ec5-a4c0-23eb6a4fa9bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-2.2.2-py3-none-any.whl (801 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/801.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.7/801.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m798.7/801.9 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m801.9/801.9 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.66.2)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch_lightning)\n",
            "  Downloading torchmetrics-1.3.2-py3-none-any.whl (841 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.5/841.5 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (24.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.11.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from pytorch_lightning)\n",
            "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.9.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->pytorch_lightning) (67.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (3.13.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->pytorch_lightning) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->pytorch_lightning) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch_lightning\n",
            "Successfully installed lightning-utilities-0.11.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 pytorch_lightning-2.2.2 torchmetrics-1.3.2\n"
          ]
        }
      ],
      "source": [
        "from typing import *\n",
        "!pip install pytorch_lightning\n",
        "from pytorch_lightning import seed_everything\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9TZUxavyzV1"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "This code is adopted from Moschella et al's work: https://github.com/lucmos/relreps?tab=readme-ov-file\n",
        "\"\"\"\n",
        "def relative_projection(x: torch.Tensor, anchors: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Compute the relative representation of x with the cosine similarity\n",
        "\n",
        "    Args:\n",
        "        x: the samples absolute latents [batch, hidden_dim]\n",
        "        anchors: the anchors absolute latents [anchors, hidden_dim]\n",
        "\n",
        "    Returns:\n",
        "        the relative representation of x. The relative representation is *not* normalized,\n",
        "        when training on relative representation it is useful to normalize it\n",
        "    \"\"\"\n",
        "    x = TF.normalize(x, p=2, dim=-1)\n",
        "    anchors = TF.normalize(anchors, p=2, dim=-1)\n",
        "    return torch.einsum(\"bm, am -> ba\", x, anchors)\n",
        "\n",
        "class LatentSpace:\n",
        "    def __init__(\n",
        "        self,\n",
        "        encoding_type: str,\n",
        "        encoder_name: str,\n",
        "        vectors: torch.Tensor,\n",
        "        ids: Sequence[int],\n",
        "    ):\n",
        "        \"\"\"Utility class to represent a generic latent space\n",
        "\n",
        "        Args:\n",
        "            encoding_type: the type of latent space, i.e. \"absolute\" or \"relative\" usually\n",
        "            encoder_name: the name of the encoder used to obtain the vectors\n",
        "            vectors: the latents that compose the latent space\n",
        "            ids: the ids associated with the vectors\n",
        "        \"\"\"\n",
        "        assert vectors.shape[0] == len(ids)\n",
        "\n",
        "        self.encoding_type: str = encoding_type\n",
        "        self.vectors: torch.Tensor = vectors\n",
        "        self.ids: Sequence[int] = ids\n",
        "        self.encoder_name: str = encoder_name\n",
        "\n",
        "    def get_anchors(self, anchor_choice: str, num_anchors: int, seed: int) -> Sequence[int]:\n",
        "        \"\"\"Adopt some strategy to select the anchors.\n",
        "\n",
        "        Args:\n",
        "            anchor_choice: the selection strategy for the anchors\n",
        "            seed: the random seed to use\n",
        "\n",
        "        Returns:\n",
        "            the ids of the chosen anchors\n",
        "        \"\"\"\n",
        "        # Select anchors\n",
        "        seed_everything(seed)\n",
        "        anchor_set = []\n",
        "        if anchor_choice == \"uniform\":\n",
        "            while (len(anchor_set) != num_anchors):\n",
        "              anchor_id = random.randint(0, len(self.ids))\n",
        "\n",
        "              if anchor_id in anchor_set:\n",
        "                # if the selected anchor is already in the set, pass\n",
        "                continue\n",
        "              elif anchor_id in en_index and anchor_id in zh_index:\n",
        "                # if the selected anchor is in training set include it\n",
        "                anchor_set.append(anchor_id)\n",
        "              else:\n",
        "                continue\n",
        "        else:\n",
        "            assert NotImplementedError\n",
        "\n",
        "        result = sorted(anchor_set)\n",
        "        return result\n",
        "\n",
        "    def to_relative(\n",
        "        self, anchor_choice: str = None, seed: int = None, anchors: Optional[Sequence[int]] = None\n",
        "    ) -> \"RelativeSpace\":\n",
        "        \"\"\"Compute the relative transformation on the current space returning a new one.\n",
        "\n",
        "        Args:\n",
        "            anchor_choice: the anchors selection strategy to use, if no anchors are provided\n",
        "            seed: the random seed to use\n",
        "            anchors: the ids of the anchors to use\n",
        "\n",
        "        Returns:\n",
        "            the RelativeSpace associated to the current LatentSpace\n",
        "        \"\"\"\n",
        "        assert self.encoding_type != \"relative\"  # TODO: for now\n",
        "        anchors = self.get_anchors(anchor_choice=anchor_choice, seed=seed) if anchors is None else anchors\n",
        "\n",
        "        anchor_latents: torch.Tensor = self.vectors[anchors]\n",
        "\n",
        "        relative_vectors = relative_projection(x=self.vectors, anchors=anchor_latents.cpu())\n",
        "\n",
        "        return RelativeSpace(vectors=relative_vectors, encoder_name=self.encoder_name, anchors=anchors, ids=self.ids)\n",
        "\n",
        "class RelativeSpace(LatentSpace):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vectors: torch.Tensor,\n",
        "        ids: Sequence[int],\n",
        "        anchors: Sequence[int],\n",
        "        encoder_name: str = None,\n",
        "    ):\n",
        "        \"\"\"Utility class to represent a relative latent space\n",
        "\n",
        "        Args:\n",
        "            vectors: the latents that compose the latent space\n",
        "            ids: the ids associated ot the vectors\n",
        "            encoder_name: the name of the encoder_name used to obtain the vectors\n",
        "            anchors: the ids associated to the anchors to use\n",
        "        \"\"\"\n",
        "        super().__init__(encoding_type=\"relative\", vectors=vectors, encoder_name=encoder_name, ids=ids)\n",
        "        self.anchors: Sequence[int] = anchors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGr5nfFsS7Yg"
      },
      "source": [
        "# 4. Create latent space and relative embeddings using chosen anchors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rj27W85-d1Ub",
        "outputId": "11878aaf-a178-489e-b05c-938dfbcb1ec1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chosen English anchors are [3, 7, 17, 20, 30, 39, 40, 45, 70, 83, 95, 100, 105, 109, 119, 137, 163, 176, 195, 214, 218, 234, 235, 247, 266, 272, 303, 329, 339, 437, 465, 489, 498, 507, 510, 525, 542, 571, 607, 657, 660, 716, 726, 727, 734, 751, 769, 784, 902, 938, 998, 1004, 1016, 1025, 1099, 1148, 1301, 1315, 1321, 1388, 1503, 1524, 1529, 1607, 1641, 1706, 1738, 1816, 1845, 1858, 1934, 1963, 2021, 2037, 2063, 2142, 2178, 2181, 2203, 2264, 2292, 2442, 2540, 2588, 2643, 2649, 2674, 2713, 2862, 2931, 2949, 2973, 2994, 3051, 3076, 3180, 3194, 3297, 3343, 3377, 3483, 3515, 3538, 3539, 3588, 3695, 3717, 3735, 3757, 3854, 3927, 4078, 4167, 4178, 4183, 4312, 4337, 4391, 4406, 4516, 4821, 4824, 4829, 5096, 5138, 5240, 5268, 5373, 5412, 5441, 5450, 5482, 5739, 5880, 5908, 6062, 6101, 6222, 6329, 6396, 6427, 6642, 6687, 6785, 6805, 6823, 6928, 6971, 7231, 7299, 7366, 7745, 7900, 7918, 8374, 8526, 8579, 8624, 8805, 8871, 8901, 9418, 9635, 9830, 9946, 10210, 10510, 10523, 10687, 10699, 11503, 11596, 11653, 12021, 12458, 12640, 13024, 13397, 13594, 13779, 14240, 14404, 14531, 14660, 15590, 16243, 16359, 17380, 17466, 17830, 18416, 18454, 21024, 23492, 25422, 30119, 35371, 39064, 40485, 46664, 49070, 52758, 137192, 335598]\n",
            "Chosen Chinese anchors are [10, 13, 13, 21, 32, 41, 49, 53, 58, 60, 61, 95, 97, 104, 111, 131, 150, 152, 160, 160, 163, 202, 231, 245, 384, 396, 458, 503, 646, 661, 672, 683, 684, 793, 824, 918, 927, 954, 970, 983, 1033, 1040, 1089, 1105, 1114, 1165, 1201, 1227, 1351, 1394, 1565, 1620, 1658, 1683, 1728, 1881, 1903, 1927, 1933, 2127, 2360, 2376, 2383, 2432, 2457, 2505, 2549, 2566, 2790, 2847, 2889, 2914, 3069, 3094, 3100, 3234, 3279, 3301, 3350, 3494, 3559, 3625, 3762, 3843, 3856, 3859, 4105, 4182, 4208, 4485, 4503, 4510, 4746, 4746, 4789, 5122, 5202, 5242, 5289, 5424, 5432, 5447, 5462, 5494, 5504, 5581, 5631, 5694, 5739, 5851, 6189, 6314, 6570, 6645, 6665, 6667, 6732, 6768, 6838, 6942, 7003, 7023, 7027, 7040, 7212, 7238, 7368, 7464, 7485, 7841, 7904, 7990, 8126, 8324, 8354, 8372, 8609, 8728, 9144, 9176, 9237, 9323, 9630, 9933, 10069, 10503, 10622, 10637, 10951, 11508, 12059, 12284, 12596, 12740, 12747, 13177, 13521, 13548, 13734, 13890, 14537, 15036, 15059, 15203, 15328, 15422, 15669, 15803, 16308, 16382, 16554, 17076, 18635, 19390, 19543, 20110, 20559, 20676, 20821, 22032, 22679, 23433, 23668, 24062, 24547, 26504, 27983, 28102, 30025, 30333, 31423, 31868, 35689, 43439, 48401, 62324, 63703, 64938, 65763, 69705, 106401, 130210, 151618, 680906]\n"
          ]
        }
      ],
      "source": [
        "# Read dictionary to memory\n",
        "def read_anchors(filePath):\n",
        "    # for reading also binary mode is important\n",
        "    with open(filePath, 'rb') as fp:\n",
        "        n_list = json.load(fp)\n",
        "        return n_list\n",
        "\n",
        "r_anchors = read_anchors(\"data/anchors_random_dim_200.json\")\n",
        "print('Chosen English anchors are', r_anchors[\"en\"])\n",
        "print('Chosen Chinese anchors are', r_anchors[\"zh\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZFgsHWVJP6P"
      },
      "outputs": [],
      "source": [
        "# Double check number of anchors are equal in English and Chinese\n",
        "assert len(r_anchors[\"en\"]) == len(r_anchors[\"zh\"])\n",
        "NUM_ANCHORS = len(r_anchors[\"en\"])\n",
        "print(\"Number of anchors =\", NUM_ANCHORS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oz5su1eT9Xy"
      },
      "outputs": [],
      "source": [
        "NUM_SAMPLES_EN = vocab_size_en\n",
        "\n",
        "en_anchors_ids = r_anchors[\"en\"]\n",
        "print(\"Selected English anchor ids are:\", en_anchors_ids)\n",
        "\n",
        "# Create English latent space from English absolute embeddings\n",
        "en_abs_embedding = torch.FloatTensor(en_embedding)\n",
        "\n",
        "en_abs_latent_space = LatentSpace(\n",
        "    encoding_type=\"absolute\",\n",
        "    encoder_name=\"english abs embedding\",\n",
        "    vectors=en_abs_embedding,\n",
        "    ids=list(range(NUM_SAMPLES_EN)),\n",
        ")\n",
        "print(\"En absolute embedding shape\", en_abs_latent_space.vectors.shape)\n",
        "\n",
        "en_rel_latent_space = en_abs_latent_space.to_relative(anchors=en_anchors_ids)\n",
        "print(\"En relative embedding shape\", en_rel_latent_space.vectors.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjcO68HBUkqh",
        "outputId": "bb238710-0142-4b20-8ab2-a8ccb222b90e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Corresponding Chinese anchor ids are: [27, 117, 181, 241, 305, 369, 405, 663, 672, 697, 714, 765, 879, 950, 968, 1229, 1301, 1360, 1431, 1437, 1560, 1716, 1766, 1847, 1889, 1903, 2014, 2186, 2253, 2325, 2335, 2816, 2821, 2884, 2934, 2951, 2976, 3032, 3033, 3124, 3165, 3366, 3377, 3411, 3514, 3585, 3590, 3702, 3768, 3852, 3915, 3915, 3968, 4130, 4228, 4327, 4353, 4435, 4449, 4452, 4595, 4608, 4627, 4894, 5094, 5119, 5144, 5399, 5476, 5620, 5794, 5823, 5825, 5840, 6140, 6536, 6928, 7430, 7522, 7531, 7594, 7745, 7853, 7937, 8008, 8453, 8831, 9040, 9131, 9455, 9635, 10487, 10721, 10869, 11032, 11099, 11383, 11720, 11770, 11931, 12013, 12353, 12827, 13065, 13414, 13585, 14010, 14179, 14331, 14684, 14705, 14791, 14897, 14939, 15402, 16276, 16460, 17304, 17551, 17672, 17821, 17834, 18048, 18203, 18248, 18597, 18718, 18732, 18990, 19036, 19276, 19458, 19562, 19568, 19789, 19999, 20080, 20410, 20810, 20946, 21730, 21744, 22370, 22502, 22531, 23188, 23312, 23944, 25036, 25263, 25420, 25441, 25877, 26585, 26681, 26835, 27461, 28493, 28832, 29205, 29303, 29352, 30148, 30457, 30478, 32212, 34712, 36882, 37263, 39382, 40491, 41262, 42333, 43414, 44198, 45017, 46526, 47629, 49224, 50434, 57127, 58400, 58855, 58866, 59802, 60824, 62331, 63557, 65757, 66861, 70924, 70978, 72150, 74098, 75419, 77827, 81354, 84069, 86063, 89327]\n",
            "Zh absolute embedding shape torch.Size([95685, 100])\n",
            "Zh relative embedding shape torch.Size([95685, 200])\n"
          ]
        }
      ],
      "source": [
        "NUM_SAMPLES_ZH = vocab_size_zh\n",
        "\n",
        "zh_anchors_ids = r_anchors[\"zh\"]\n",
        "print(\"Corresponding Chinese anchor ids are:\", zh_anchors_ids)\n",
        "\n",
        "zh_abs_embedding = torch.FloatTensor(zh_embedding)\n",
        "\n",
        "zh_abs_latent_space = LatentSpace(\n",
        "    encoding_type=\"absolute\",\n",
        "    encoder_name=\"chinese abs embedding\",\n",
        "    vectors=zh_abs_embedding,\n",
        "    ids=list(range(NUM_SAMPLES_ZH)),\n",
        ")\n",
        "\n",
        "# The shape is [num_samples, hidden_dim]\n",
        "print(\"Zh absolute embedding shape\", zh_abs_latent_space.vectors.shape)\n",
        "\n",
        "# Transform Chinese absolute latent space to relative latent space using the anchors chosen\n",
        "zh_rel_latent_space = zh_abs_latent_space.to_relative(anchors=zh_anchors_ids)\n",
        "print(\"Zh relative embedding shape\", zh_rel_latent_space.vectors.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJDdmZsiT5Ik"
      },
      "source": [
        "# 5. Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFn8FqLRzlOT"
      },
      "outputs": [],
      "source": [
        "class ZhZhAutoencoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Autoencoder to learn the weights connecting Chinese\n",
        "    embeddings back to one-hot vectors. Initialize the\n",
        "    weights connecting the embeddings and one-hot vectors\n",
        "    with the transpose of the weights from the Tecent\n",
        "    pretrained model, connecting the one-hot vector and\n",
        "    embedding, to speed up training.\n",
        "    \"\"\"\n",
        "    def __init__(self, pretrained):\n",
        "        super(ZhZhAutoencoder, self).__init__()\n",
        "\n",
        "        # Save the pretrained embedding within the model\n",
        "        # load pretrained embeddings and freeze them\n",
        "        self.weights    = torch.FloatTensor(pretrained.vectors)\n",
        "        self.encoder    = nn.Embedding.from_pretrained(self.weights, freeze = True)\n",
        "\n",
        "        # Make a copy of the pretrained weights and use them in the following layers\n",
        "        copy_pretrained = copy.deepcopy(pretrained)\n",
        "        self.copyweight = torch.FloatTensor(copy_pretrained.vectors)\n",
        "        self.decoder    = nn.Parameter(self.copyweight.t())\n",
        "\n",
        "    def forward(self, text):\n",
        "        \"\"\"The pipeline that takes input values through the network\"\"\"\n",
        "        # Find the embeddings for text\n",
        "        trained_embed = self.encoder(text)\n",
        "\n",
        "        # Turn embedding back to one-hot\n",
        "        one_hot       = trained_embed @ self.decoder\n",
        "\n",
        "        return one_hot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uh8oShrxTdkc"
      },
      "source": [
        "# 6. Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cC2TIERnnCZ9"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def timeSince(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ErdpxcLE79c"
      },
      "outputs": [],
      "source": [
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "def train(model,\n",
        "          train_history,\n",
        "          modelFilePath,\n",
        "          num_epochs,\n",
        "          optimizer,\n",
        "          criterion,\n",
        "          batch_size,\n",
        "          train_loader,\n",
        "          base_lr,\n",
        "          final_lr):\n",
        "  avg_loss = []\n",
        "  start = time.time()\n",
        "  scheduler = CosineAnnealingLR(\n",
        "        optimizer,\n",
        "        T_max=num_epochs,\n",
        "        eta_min=final_lr\n",
        "    )\n",
        "\n",
        "  print(\"\\n-----Batch Size =\", batch_size, \"NUM_ANCHORS =\", NUM_ANCHORS, file=open(train_history, 'a'))\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    losses = 0\n",
        "    loop = tqdm(enumerate(train_loader), total=len(train_loader), leave=False)\n",
        "    print('\\nEpoch: %d \\nPercent Finished: %d%% Time Elapsed: %s' % (epoch, epoch / num_epochs * 100, timeSince(start)), file=open(train_history, 'a'))\n",
        "    for batch_idx, (word, index) in loop:\n",
        "      # Clear gradients w.r.t. parameters\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      index = index.to(device)\n",
        "\n",
        "      # Forward pass to get output/logits\n",
        "      outputs_train = model(index)\n",
        "\n",
        "      # Calculate Loss: softmax --> cross entropy loss\n",
        "      loss = criterion(outputs_train, index)\n",
        "      losses += loss.item()\n",
        "\n",
        "      # Getting gradients w.r.t. parameters\n",
        "      loss.backward()\n",
        "\n",
        "      # Updating parameters\n",
        "      optimizer.step()\n",
        "\n",
        "      # update progress bar\n",
        "      loop.set_description(f\"Epoch: [{epoch}/{num_epochs}]\")\n",
        "      loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg = losses / vocab_size_zh\n",
        "    avg_loss.append(avg)\n",
        "\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = scheduler(epoch)\n",
        "        print(\"Learning rate is now\", param_group['lr'], file=open(train_history, 'a'))\n",
        "\n",
        "    print(\"   Loss: {:.15f}\".format(avg), file=open(train_history, 'a'))\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': avg_loss,\n",
        "        'learning_rate': param_group['lr']\n",
        "        }, modelFilePath)\n",
        "\n",
        "  print(\"Finish training!\", file=open(train_history, 'a'))\n",
        "  return avg_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "og1jvjraLUdr",
        "outputId": "60b411fd-488b-4cdd-bdb1-a351674828cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Using {} device'.format(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GL5fezZSYa_z"
      },
      "outputs": [],
      "source": [
        "zhzhmodel = ZhZhAutoencoder(zh_rel_latent_space).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(zhzhmodel.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfLAWJkt59Re"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 4096\n",
        "\n",
        "training_data = TrainData(vocab_zh)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=training_data,\n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           shuffle=True,\n",
        "                                           collate_fn=collate_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdJnCghmDjiY"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCH = 100\n",
        "\n",
        "loss = train(zhzhmodel,\n",
        "            'record/zhzhautoencoder.txt',\n",
        "            'ckpt/zhzhautoencoder.pt',\n",
        "            NUM_EPOCH,\n",
        "            optimizer,\n",
        "            criterion,\n",
        "            BATCH_SIZE,\n",
        "            train_loader,\n",
        "            base_lr=0.001,\n",
        "            final_lr=0.0001)\n",
        "\n",
        "# save the losses in the pickle file\n",
        "import pickle\n",
        "with open('record/zhzhautoencoder.pkl', 'wb') as file:\n",
        "\n",
        "    # A new file will be created\n",
        "    pickle.dump(loss, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "TrWc_uQ2WXCC",
        "outputId": "b475dbd9-46f8-42e9-f967-76103a8b56af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x79cf4159a9b0>"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "xtrain = np.arange(NUM_EPOCH)\n",
        "plt.plot(xtrain, loss, label = \"Training Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.title(\"ZH Rel to Abs Autoencoder\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVEWC6pC6oKM"
      },
      "source": [
        "# 11. Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTP2jK_Q8otN"
      },
      "outputs": [],
      "source": [
        "state = torch.load('ckpt/zhzhautoencoder.pt')\n",
        "zhzhmodel.load_state_dict(state['model_state_dict'])\n",
        "optimizer.load_state_dict(state['optimizer_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWoX6Mct6vQc"
      },
      "outputs": [],
      "source": [
        "# Get a single sample\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=training_data,\n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           shuffle=True,\n",
        "                                           collate_fn=collate_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrFxXWkq60RW",
        "outputId": "00c4a8ca-123d-4271-d088-b9729b4b0bf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random word: ['特洛伊']\n",
            "Model prediction: 特洛伊\n"
          ]
        }
      ],
      "source": [
        "test = next(iter(train_loader))\n",
        "print(\"Random word:\", test[0])\n",
        "pos = torch.argmax(zhzhmodel(test[1].to(device)))\n",
        "print(\"Model prediction:\", vocab_zh[pos])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}