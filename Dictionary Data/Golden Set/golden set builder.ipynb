{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Golden Set!\n",
    "\n",
    "# So our \"golden set\" takes the form of a JSON dictionary\n",
    "# {eng word: chn word, eng word: chn word, eng word: chn word... } etc.\n",
    "# We'll be taking this golden set from 4 different dictionaries\n",
    "# Yabla, Cambridge, MDBG, and the Facebook AI set\n",
    "\n",
    "# First we compile a set of ALL english keys from every data set\n",
    "import json\n",
    "\n",
    "with open(\"cambridge/cambridge dict jsons/processed cdict.json\", encoding=\"utf-8-sig\") as in_file:\n",
    "    cdict = json.load(in_file)\n",
    "    cdictWords = list(cdict.keys())\n",
    "\n",
    "with open(\"MDBG/mdbg dict jsons/processed mdbg dict.json\", encoding=\"utf-8-sig\") as in_file:\n",
    "    mdbgdict = json.load(in_file)\n",
    "    mdbgWords = list(mdbgdict.keys())\n",
    "\n",
    "with open(\"yabla/yabla dict jsons/full yabla dict.json\", encoding=\"utf-8-sig\") as in_file:\n",
    "    ydict = json.load(in_file)\n",
    "    ydictWords = list(ydict.keys())\n",
    "\n",
    "with open(\"processed enzhDict.json\", encoding=\"utf-8-sig\") as in_file:\n",
    "    facebookDict = json.load(in_file)\n",
    "    facebookWords = list(facebookDict.keys())\n",
    "\n",
    "allWords = list(set(cdictWords + mdbgWords + ydictWords + facebookWords))\n",
    "\n",
    "with open(\"allWords.txt\", \"w\", encoding=\"utf-8-sig\") as out_file:\n",
    "    out_file.write(\"\\n\".join(allWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we check all four to see the text equivalents\n",
    "# If a word has the same translation in AT LEAST three datasets:\n",
    "# add to golden set dictionary\n",
    "# else, continue\n",
    "# we can make quick modifications to input word to golden set if it has same translation\n",
    "# in at least two, but this would involve dealing with possible ties\n",
    "\n",
    "goldenSet = {}\n",
    "\n",
    "for word in allWords:\n",
    "    cdictEquiv = cdict.get(word)\n",
    "    mdbgdictEquiv = mdbgdict.get(word)\n",
    "    ydictEquiv = ydict.get(word)\n",
    "    facebookEquiv = facebookDict.get(word)\n",
    "\n",
    "    # Makes temporary list with all four translation equivalents\n",
    "    temp = [cdictEquiv, mdbgdictEquiv, ydictEquiv, facebookEquiv]\n",
    "\n",
    "    wordCounts = dict()\n",
    "    # Making a word count dictionary for each equivalent in the list\n",
    "    for chnWord in temp:\n",
    "        if chnWord == None:\n",
    "            continue\n",
    "        wordCounts[chnWord] = wordCounts.get(chnWord, 0) + 1\n",
    "\n",
    "    # Adding a ENG-ZH pair to the golden set if it occurs in 3 or more dictionaries\n",
    "    for count in wordCounts:\n",
    "        if wordCounts[count] >= 3:\n",
    "            goldenSet[word] = count\n",
    "\n",
    "with open(\"full golden set.json\", \"w\", encoding=\"utf-8-sig\") as out_file:\n",
    "    json.dump(goldenSet, out_file, indent=4, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
