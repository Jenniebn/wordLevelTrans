{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Golden Set!\n",
    "\n",
    "# So our \"golden set\" takes the form of a JSON dictionary\n",
    "# {eng word: chn word, eng word: chn word, eng word: chn word... } etc.\n",
    "# We'll be taking this golden set from 4 different dictionaries\n",
    "# Yabla, Cambridge, MDBG, and the Facebook AI set\n",
    "\n",
    "# First we compile a set of ALL english keys from every data set\n",
    "import json\n",
    "\n",
    "with open(\"../Cambridge/JSON Data/full cdict three senses.json\", encoding=\"utf-8-sig\") as in_file:\n",
    "    cdict = json.load(in_file)\n",
    "    cdictWords = list(cdict.items())\n",
    "\n",
    "with open(\"../MDBG/JSON Data/full mdbg dict three senses.json\", encoding=\"utf-8-sig\") as in_file:\n",
    "    mdbgdict = json.load(in_file)\n",
    "    mdbgWords = list(mdbgdict.items())\n",
    "\n",
    "with open(\"../Yabla/JSON Data/yabla dict jsons/full yabla dict.json\", encoding=\"utf-8-sig\") as in_file:\n",
    "    ydict = json.load(in_file)\n",
    "    ydictWords = list(ydict.items())\n",
    "\n",
    "with open(\"../processed enzhDict.json\", encoding=\"utf-8-sig\") as in_file:\n",
    "    facebookDict = json.load(in_file)\n",
    "    facebookWords = list(facebookDict.items())\n",
    "allWords = cdictWords + mdbgWords + ydictWords + facebookWords\n",
    "\n",
    "# with open(\"allWords.txt\", \"w\", encoding=\"utf-8-sig\") as out_file:\n",
    "#       out_file.write(\"\\n\".join(allWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we check all four to see the text equivalents\n",
    "# If a word has the same translation in AT LEAST three datasets:\n",
    "# add to golden set dictionary\n",
    "# else, continue\n",
    "# we can make quick modifications to input word to golden set if it has same translation\n",
    "# in at least two, but this would involve dealing with possible ties\n",
    "\n",
    "goldenSet = {}\n",
    "\n",
    "for pair in allWords:\n",
    "    (key, senselist) = pair\n",
    "    for sense in senselist:\n",
    "        cdictEquiv = cdict.get(key)\n",
    "        mdbgdictEquiv = mdbgdict.get(key)\n",
    "        ydictEquiv = ydict.get(key)\n",
    "        facebookEquiv = facebookDict.get(key)\n",
    "\n",
    "        # Makes temporary list with all four translation equivalents\n",
    "        temp = [cdictEquiv, mdbgdictEquiv, ydictEquiv, facebookEquiv]\n",
    "\n",
    "        wordCounts = dict()\n",
    "        # Making a word count dictionary for each equivalent in the list\n",
    "        for wordlist in temp:\n",
    "            if wordlist == None:\n",
    "                continue\n",
    "            for chnWord in wordlist:\n",
    "                if chnWord == None:\n",
    "                    continue\n",
    "                if chnWord != sense:\n",
    "                    continue\n",
    "                wordCounts[chnWord] = wordCounts.get(chnWord, 0) + 1\n",
    "                \n",
    "\n",
    "        # Adding a ENG-ZH pair to the golden set if it occurs in 3 or more dictionaries\n",
    "        for count in wordCounts:\n",
    "            if wordCounts[count] >= 3:\n",
    "                if goldenSet.get(key) == None:\n",
    "                    goldenSet[key] = [count]\n",
    "                elif count not in goldenSet.get(key):\n",
    "                    goldenSet[key].append(count)\n",
    "\n",
    "with open(\"full golden set.json\", \"w\", encoding=\"utf-8-sig\") as out_file:\n",
    "    json.dump(goldenSet, out_file, indent=4, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
